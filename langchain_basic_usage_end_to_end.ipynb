{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Retrieve API keys from environment variables\n",
    "api_key_openai = os.getenv(\"OPENAI_API_KEY\") # OpenAI API Key\n",
    "api_key_huggingface = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\") # Hugging Face Hub API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Temperature** value indicates how creative or deterministic the model's response should be.\n",
    "* A value closer to 1 will make the responses more creative (higher variability).\n",
    "* A value closer to 0 will make the responses more deterministic and consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI LLM (Language Model) with specific model and temperature\n",
    "\n",
    "# temperature=0.7 provides a balance between creativity and consistency.\n",
    "\n",
    "llm = OpenAI(model= 'gpt-3.5-turbo-instruct', api_key=api_key_openai, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Historical significance: Armero was once a thriving town in the Colombian Andes, known for its agriculture, textiles, and pottery. It was also an important transportation hub, connecting different regions of Colombia. However, in 1985, the town was completely destroyed by the eruption of the nearby Nevado del Ruiz volcano, resulting in one of the worst natural disasters in Colombian history.\n",
      "\n",
      "2. Symbol of resilience: Despite the devastating effects of the volcano eruption, the people of Armero have shown great resilience and have rebuilt the town in a new location. The town serves as a reminder of the strength and determination of its people in the face of adversity.\n",
      "\n",
      "3. Agricultural production: Armero is located in the fertile Tolima region, known for its production of rice, coffee, and other crops. The town's agricultural production helps to sustain the local economy and provide employment for its residents.\n",
      "\n",
      "4. Ecotourism: The new town of Armero is surrounded by beautiful natural landscapes, including the Nevado del Ruiz National Park. This makes it a popular destination for ecotourism, attracting visitors who are interested in hiking, bird-watching, and other outdoor activities.\n",
      "\n",
      "5. Cultural heritage: Armero is also known for its traditional\n"
     ]
    }
   ],
   "source": [
    "# Example usage: Asking the model a simple question\n",
    "\n",
    "text = \"What is the importance of Armero municiplity of Colombia?\"\n",
    "\n",
    "print(llm.invoke(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you can link users to the official documentation for more details about HuggingFaceHub and LangChain\n",
    "[LangChain-HuggingFace](https://python.langchain.com/v0.2/api_reference/huggingface/llms/langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the HuggingFace LLM using the HuggingFaceHub class\n",
    "\n",
    "llm_huggingface = HuggingFaceHub(\n",
    "    repo_id=\"google/flan-t5-large\", \n",
    "    huggingfacehub_api_token = api_key_huggingface,\n",
    "    model_kwargs={\"temperature\":0.7, \"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "important in the history of Colombia\n"
     ]
    }
   ],
   "source": [
    "output = llm_huggingface.predict(\"What is the importance of Armero municiplity of Colombia?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The output of this model may be just a single word or very concise, which is common with some open-source models (like Hugging Face's) compared to larger proprietary models like OpenAI's GPT-3 or GPT-4.\n",
    "\n",
    " - Hugging Face models (especially open-source ones) can be limited in terms of output verbosity or quality when compared to proprietary models like those from OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk credit is a problem that has been a source of controversy in finance for decades .\n"
     ]
    }
   ],
   "source": [
    "output = llm_huggingface.predict(\"Could you write a cientific description about the problem of risk credit?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Risk credit is a complex and multifaceted issue that has been a concern for financial institutions and consumers alike. It refers to the potential for financial losses that may occur when a borrower is unable to repay their debts, resulting in default or bankruptcy. This problem has become increasingly prevalent in recent years, as the global economy has become more interconnected and the availability of credit has expanded.\n",
      "\n",
      "One of the key factors that contribute to the problem of risk credit is the uncertainty surrounding the creditworthiness of borrowers. Creditworthiness is a measure of a borrower's ability and willingness to repay their debts. It is typically evaluated based on factors such as credit history, income, and assets. However, these factors can be difficult to assess accurately, as they are subject to change and may not always reflect a borrower's true financial situation.\n",
      "\n",
      "Another factor that contributes to the problem of risk credit is the complexity of financial products and services. With the rise of financial innovation, there has been an increase in the number and variety of credit products available to consumers. This has made it more challenging for both borrowers and lenders to understand the risks involved in a particular credit transaction. As a result, borrowers may take on more debt than they can realistically manage, and lenders may underestimate the potential for default.\n",
      "\n",
      "The problem\n"
     ]
    }
   ],
   "source": [
    "# To compare, let's use the previously defined llm from OpenAI to generate a response for the same question\n",
    "\n",
    "print(llm.invoke(\"Could you write a cientific description about the problem of risk credit?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Templates and LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt templates help to translate user input and parameters into instructions for a language model. \n",
    "\n",
    "[Oficial Documentation](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.prompt.PromptTemplate.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the importance of the municipality of Armero Colombia '"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a prompt template that accepts the input variable `city`\n",
    "# The template is a sentence where we can insert the name of a city\n",
    "\n",
    "prompt_template=PromptTemplate(input_variables=['city'], # The variable we will replace in the template\n",
    "                                template=\"Tell me the importance of the municipality of {city} Colombia \")\n",
    "\n",
    "# Example of how to format the prompt with a specific city\n",
    "prompt_template.format(city=\"Armero\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the use of `PromptTemplate` allow to dynamically generate prompts based on the city input. This makes it easy to reuse the same structure with different city names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the LLM with the Prompt using Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chains allow you to combine multiple components that you need to execute. In this case, we combine the LLM and the prompt template using an `LLMChain`.\n",
    "\n",
    "The chain will take the prompt, fill it with the input, and run it through the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Historical significance: The municipality of Armero is located in the Tolima department of Colombia and is known for its tragic history. In 1985, the town was completely destroyed by the eruption of the Nevado del Ruiz volcano, resulting in the death of over 20,000 people. This event is considered one of the worst natural disasters in Colombia's history and has had a lasting impact on the country.\n",
      "\n",
      "2. Agricultural hub: Armero is situated in a fertile valley known as the \"Cradle of Colombia's Agriculture\" due to its rich soil and favorable climate. The town is a major producer of rice, coffee, and sugar cane, and its agricultural products are essential to the economy of the region.\n",
      "\n",
      "3. Cultural diversity: Armero is home to a diverse population, including indigenous communities such as the Pijaos and Guambianos, as well as descendants of African slaves. This cultural diversity has contributed to the town's unique traditions, cuisine, and festivals, making it a vibrant and dynamic place to visit.\n",
      "\n",
      "4. Ecotourism destination: The municipality of Armero is surrounded by beautiful natural landscapes, including the Nevado del Ruiz National Park and the Los Nevados Natural Park. These areas offer opportunities for\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Define a chain that combines the LLM and the prompt template\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template) # OpenAI\n",
    "\n",
    "print(chain.run(\"Armero\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The municipality has a population of .\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm_huggingface, prompt=prompt_template) # HuggingFace\n",
    "print(chain.run(\"Armero\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "\n",
    "- `LLMChain` is a powerful way to combine prompts with LLMs, allowing you to reuse prompts efficiently across multiple inputs.\n",
    "\n",
    "- The `chain.run()` method passes the formatted prompt to the LLM and returns the generated response.\n",
    "\n",
    "- You can easily adapt this chain to other cities by changing the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Multiple Chains Using SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first prompt asks for the largest country in a specific continent.\n",
    "\n",
    "continent_prompt = PromptTemplate(\n",
    "    input_variables=['continent'], # Input variable is the continent name\n",
    "    template=\"Please tell me what is the largest country in {continent}\"\n",
    ")\n",
    "\n",
    "# The first chain uses the continent_prompt and the LLM\n",
    "\n",
    "capital_chain=LLMChain(llm=llm, prompt=continent_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second prompt asks for the most beautiful natural landscapes in the country\n",
    "\n",
    "country_template=PromptTemplate(\n",
    "    input_variables=['country'], \n",
    "    template=   \"Tell me about the 5 most beautiful natural landscapes in {country}.\"\n",
    "                \"Please also remind me which country you are talking about.\"\n",
    ")\n",
    "\n",
    "# Create the second chain using the country_template\n",
    "\n",
    "country_chain=LLMChain(llm=llm, prompt=country_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both chains sequentially\n",
    "# The output of the first chain will automatically beocme the input for the second chain\n",
    "\n",
    "chain = SimpleSequentialChain(chains=[capital_chain, country_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Chain Output \n",
      "\n",
      "1. Banff National Park, Canada\n",
      "Located in the Rocky Mountains of Alberta, Banff National Park is known for its stunning natural landscapes. It is home to turquoise lakes, snow-capped mountains, and lush forests. The most famous attraction in the park is Lake Louise, with its crystal clear waters and panoramic views of the surrounding mountains.\n",
      "\n",
      "2. Torres del Paine National Park, Chile\n",
      "Located in the Patagonia region of Chile, Torres del Paine National Park is known for its rugged beauty. The park is home to towering granite peaks, glaciers, and turquoise lakes. The most famous landmark in the park is the three granite towers, which give the park its name.\n",
      "\n",
      "3. Plitvice Lakes National Park, Croatia\n",
      "Located in central Croatia, Plitvice Lakes National Park is a UNESCO World Heritage Site known for its cascading lakes and waterfalls. The park is home to sixteen interconnected lakes, each with its own distinct color due to the minerals and organisms in the water.\n",
      "\n",
      "4. Zhangjiajie National Forest Park, China\n",
      "Located in the Hunan Province of China, Zhangjiajie National Forest Park is known for its unique rock formations and breathtaking views. The park is home to thousands of towering sandstone pillars, some rising over\n"
     ]
    }
   ],
   "source": [
    "# Execute the chain with a continent as input. For example, \"South America\".\n",
    "# The first chain will return the largest country (e.g., Brazil),\n",
    "# and the second chain will use this country to return a list of 5 beautiful landscapes\n",
    "\n",
    "output = chain.run(\"North America\")\n",
    "\n",
    "print(\"Combined Chain Output\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are Chains in LangChain and Why are they necessary?**\n",
    "\n",
    "Chains allow you to connect multiple steps or prompts in a logical sequence, where the output of one step (chain) becomes the input of the next step. This structure is essential for automating more complex tasks that requires multiple pieces of information to be processes in stages.\n",
    "\n",
    "**Why are Chains Necessary?**\n",
    "* Structure Complex Interactions: When the output of one prompt is needed as the input for another, chains automatically manage this process.\n",
    "\n",
    "* Modularity: You can break down a large task into smaller, manageable steps (chains). This makes the code reusable and easier to debug.\n",
    "\n",
    "* Flexibility: Chains can be compossed in various ways (sequential, parallel, etc.) to suit different use cases, making it easier to handle complex workflows involving multiple logical steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It allows you to run multiple chains in a sequence where each chain can use the outputs of previous chains. Unlike `SimpleSequentialChain`, which passes only the final output of one chain to the next, `SequentialChain` allows more control by managing multiple input and output variables across the entire sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain, LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(\n",
    "    input_variables=['country'],\n",
    "    template=\"Please tell me the capital of the {country}\")\n",
    "\n",
    "# The first chain will take a country and return its capital\n",
    "# The `output_key` is used to define the name of the output variable, which will be passed to the next chain\n",
    "\n",
    "capital_chain=LLMChain(llm=llm, prompt=capital_prompt, output_key=\"capital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the second chain (Capita -> Historical Events)\n",
    "\n",
    "# This chain takes the capital as input and returns important historical events in that city\n",
    "\n",
    "famous_template=PromptTemplate(\n",
    "    input_variables=['capital'], # Input is the capital returned from the first chain\n",
    "    template=\"Tell me some important history events in {capital}\") # Asking for historical events\n",
    "\n",
    "# The second chain will take the capital from the first chain and return historical events related to that capital\n",
    "famous_chain = LLMChain(llm=llm, prompt=famous_template, output_key=\"places\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine chains using `SequentialChain`\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains=[capital_chain, famous_chain],\n",
    "    input_variables=['country'], # Input to the entire chain is the country\n",
    "    output_variables=['capital', 'places']) # Outputs we expect: capital and historical events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain({'country':\"Colombia\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'Colombia', 'capital': '\\n\\nThe capital of Colombia is Bogotá.', 'places': '\\n\\n1. Foundation of Bogotá (1538): The city of Bogotá was founded on August 6, 1538 by Spanish conquistador Gonzalo Jiménez de Quesada.\\n\\n2. Spanish colonial rule (1538-1819): Bogotá served as the capital of the Spanish colonial Viceroyalty of New Granada, which included present-day Colombia, Venezuela, Ecuador, and Panama.\\n\\n3. Independence from Spain (1819): On July 20, 1810, the citizens of Bogotá declared their independence from Spanish rule. This eventually led to the formation of the Republic of Colombia in 1819.\\n\\n4. La Violencia (1948-1958): A period of political and social violence known as \"La Violencia\" broke out in Colombia after the assassination of Liberal leader Jorge Eliécer Gaitán in Bogotá in 1948.\\n\\n5. Bogotazo (1948): Following the assassination of Gaitán, riots and protests erupted in Bogotá, leading to widespread destruction and violence. This event is known as the \"Bogotazo.\"\\n\\n6. The National Front (1958-1974): A political agreement known as the National Front was signed in Bog'}\n"
     ]
    }
   ],
   "source": [
    "print(chain({'country':\"Colombia\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capital: \n",
      "\n",
      "The capital of Colombia is Bogotá.\n",
      "\n",
      "\n",
      "Historical Events in Capital:  Some important historical events in Bogotá include:\n",
      "\n",
      "1. The founding of Bogotá: The city was founded on August 6, 1538 by Spanish conquistador Gonzalo Jiménez de Quesada.\n",
      "\n",
      "2. Independence from Spain: On July 20, 1810, Bogotá played a crucial role in the Colombian War of Independence when a group of patriots declared independence from Spanish rule.\n",
      "\n",
      "3. The Battle of Boyacá: On August 7, 1819, the Battle of Boyacá took place near Bogotá, resulting in the defeat of Spanish forces and the establishment of the Republic of Gran Colombia.\n",
      "\n",
      "4. The Bogotazo: On April 9, 1948, the assassination of popular liberal leader Jorge Eliécer Gaitán sparked riots and civil unrest in Bogotá, known as the Bogotazo, which led to the Colombian Civil War.\n",
      "\n",
      "5. The National Front: In 1958, the National Front was established in Bogotá, bringing an end to the Colombian Civil War and ushering in a period of political stability and economic growth.\n",
      "\n",
      "6. The Palace of Justice siege: In 1985, the M-19 guerrilla group stormed the Palace of Justice in\n"
     ]
    }
   ],
   "source": [
    "print(\"Capital:\", output['capital']) \n",
    "print(\"\\n\")\n",
    "print(\"Historical Events in Capital:\", output['places'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Models With ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we demonstrate how to use `ChatOpenAI` for handling conversational AI tasks.\n",
    "Unlike standard `OpenAI` models (which handle plain completions), `ChatOpenAI` models specialize in dialogue-based interactions, where context is maintained between user (HumanMessage) and AI responses (AIMessage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ChatOpenAI class, which is designed for chat-based models.\n",
    "\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import message types that define the interaction structure in conversations\n",
    "\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference Between ChatOpenAI and OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `OpenAI`: Designed for general text completions (e.g., predicting the next text based on an input).\n",
    "It is useful for generating single-turn responses (like text generation, Q&A without a conversational flow).\n",
    "\n",
    "- `ChatOpenAI`: Designed for multi-turn conversations. It uses message types (SystemMessage, HumanMessage, AIMessage) to simulate an ongoing conversation, where context from previous messages can influence the AI's response.\n",
    "This is ideal for chatbots or any situation where maintaining context is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatllm_openai = ChatOpenAI(model= 'gpt-3.5-turbo', api_key=api_key_openai, temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structure of a Conversation with ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A conversation with `ChatOpenAI` is represented as a series of messages:\n",
    "* `SystemMessage`: Used to set the role or instructions for the AI (e.g., \"You are a Geologist AI Assistant\").\n",
    "* `HumanMessage`: Represents a message sent by the user (in this case, the question or prompt from the user).\n",
    "* `AIMessage`: This would be the AI's response, although it's not explicity needed here since the LLM will generate it.\n",
    "\n",
    "----------------\n",
    "\n",
    "In this example, we simulate a conversation where:\n",
    "- The AI is instructed to act as a Geologist AI Assistant.\n",
    "- The human asks the AI to tell a story about the top 5 most important geological disasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_openai.chat_models.base.ChatOpenAI"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chatllm_openai([\n",
    "SystemMessage(content=\"You are a Geologist AI Assistant\"),\n",
    "HumanMessage(content=\"Please make a story telling about the top 5 most important geological distastars\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Certainly! Here is a story about the top 5 most important geological disasters:\\n\\nOnce upon a time, the Earth was a dynamic and ever-changing planet, prone to a variety of geological disasters that have shaped its landscape and impacted the lives of those living on it. Here are the top 5 most important geological disasters in Earth's history:\\n\\n1. The eruption of Mount Vesuvius in 79 AD: One of the most famous volcanic eruptions in history, Mount Vesuvius buried the Roman cities of Pompeii and Herculaneum in ash and pumice, preserving them for centuries and providing valuable insights into ancient Roman life and culture.\\n\\n2. The Great Lisbon Earthquake of 1755: Striking on All Saints' Day, this devastating earthquake and subsequent tsunami destroyed much of the city of Lisbon, Portugal, and caused widespread damage throughout Europe. It prompted a reevaluation of earthquake preparedness and led to advancements in the study of seismology.\\n\\n3. The eruption of Krakatoa in 1883: The eruption of Krakatoa, located in present-day Indonesia, was one of the most powerful volcanic events in recorded history. The explosion generated tsunamis that killed tens of thousands of people and caused a global decrease in temperatures due to the release of ash and sulfur dioxide into the atmosphere.\\n\\n4. The 2004 Indian Ocean Tsunami: Triggered by a massive undersea earthquake off the coast of Sumatra, the Indian Ocean Tsunami devastated coastal communities in several countries, killing over 230,000 people and causing widespread destruction. The disaster highlighted the importance of early warning systems and preparedness for tsunamis.\\n\\n5. The Deepwater Horizon Oil Spill in 2010: While not a traditional geological disaster, the Deepwater Horizon oil spill in the Gulf of Mexico was a significant environmental catastrophe with geological implications. The spill released millions of barrels of oil into the ocean, causing widespread damage to marine ecosystems and highlighting the risks associated with offshore drilling.\\n\\nThese geological disasters serve as reminders of the Earth's power and unpredictability, as well as the importance of understanding and mitigating the risks posed by natural hazards. Through continued research and preparedness efforts, we can work towards minimizing the impact of future geological disasters and protecting the planet and its inhabitants.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 462, 'prompt_tokens': 34, 'total_tokens': 496, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-41b5c64f-f677-4eba-a116-e0525742f506-0', usage_metadata={'input_tokens': 34, 'output_tokens': 462, 'total_tokens': 496})"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template + LLM + Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This parser will take the AI´s response (a string with comma-separated words) and split it into a list of words using `split()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self,text:str):\n",
    "        # The parser will split the response based on commas and return a list of words\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Prompt Template\n",
    "\n",
    "template=\"You are a helpfull assistant. When the use give any input, you should generate five words in a comma separated list\"\n",
    "human_template = \"{text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a ChatPromptTemplase that structures the conversation\n",
    "\n",
    "chatprompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template), # System message (instructions for the AI)\n",
    "    (\"human\", human_template) # Human input (dynamic text)   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain= chatprompt | chatllm_openai | Commaseperatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' bright', ' astute', ' brainy']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
